---
title: "Assignment 10 social media"
output: html_document
date: "2024-04-26"
---

Loading Data:
```{R}
library(MASS)
library(ggplot2)
library(memisc)
library(ROCR)
library(dplyr)
library(klaR)
```
```{r}
library(readxl)
social_media <- read_excel("C:/Users/Vishal/Downloads/MVA_CLASS_COMBINE.xlsx")
social_media
str(social_media)
social_media_cleaned <- social_media[,-1]

```



changing column names:


```{R}

#changing column names
change_cols_index <- c(2,4,6,8,10,12,14,16,17,18,19,20,21,22,23,24)
change_cols_name <- c("Instagram_Time", "Linkedin_Time", "Snapchat_Time", "Twitter_Time", "Whatsapp_Time", "Youtube_Time", "OTT_Time", "Reddit_Time", "Application Type", "Interview_call_received", "Networking", "Learning", "Mood_Productivity", "Morning_tireness", "Morning_tireness", "Weekly_Feelings")
colnames(social_media_cleaned)[change_cols_index] <- change_cols_name



social_media_cleaned


```



Cleaning Data:

Cleaning Null values

```{R}
# Convert "NA", "N/A", "n/a", "na", "N.A", "n.a" to 0
social_media_cleaned[social_media_cleaned == "NA" | social_media_cleaned == "N/A" | social_media_cleaned == "na" | social_media_cleaned == "n/a" | social_media_cleaned == "N.A" | social_media_cleaned == "n.a" | social_media_cleaned == "0" | social_media_cleaned == ""] <- NA
social_media_cleaned

```


Null values converted to 0

```{R}
social_media_cleaned[is.na(social_media_cleaned)] <- '0'
social_media_cleaned
```


Keeping relevant columns only:
All time columns + label to predict ("How did you feel enitre week") + Application type

```{R}
# Define a function to convert time strings to decimal hours
convert_to_decimal_hours <- function(time_string) {
# Check if NA values are present
if (any(is.na(time_string))) {
         return(rep(NA, length(time_string)))  # Return NA for NA values
     }
     
# Define a function to convert HH:MM format to decimal hours
     hhmm_to_decimal <- function(hhmm) {
         parts <- as.numeric(strsplit(hhmm, ":")[[1]])  # Split into hours and minutes
         hours <- parts[1]
         minutes <- ifelse(length(parts) > 1, parts[2], 0)  # Handle missing minutes
         total_hours <- hours + minutes / 60
         return(total_hours)
     }
     
# Convert time strings to decimal hours
decimal_hours <- sapply(time_string, function(x) {
         if (grepl("^\\d+:\\d+$", x)) {
             return(hhmm_to_decimal(x))  # Convert HH:MM format
         } else if (grepl("^\\d+\\.\\d+$", x)) {
             return(as.numeric(x))  # Convert decimal format
         } else if (grepl("^\\d+$", x)) {
             return(as.numeric(x))  # Convert whole numbers
         } else {
             return(NA)  # Return NA for other cases
         }
     })
     
     return(decimal_hours)
}

time_columns <- c("Instagram_Time", "Linkedin_Time", "Snapchat_Time", "Twitter_Time", "Whatsapp_Time", "Youtube_Time", "OTT_Time", "Reddit_Time") 
# Apply the conversion function to all time columns
social_media_cleaned[time_columns] <- lapply(social_media_cleaned[time_columns], convert_to_decimal_hours)
 
# Verify the result
str(social_media_cleaned)

#Dropping the name columns
social_media_cleaned <- social_media_cleaned[, -c(1, 3, 5, 7, 9, 11, 13, 15)] 
social_media_cleaned
```

Data Preporcessing:

Replace mean value with null values for data preprocessing

```{R}
# Loop through each column in time_columns
social_media_cleaned[time_columns] <- lapply(social_media_cleaned[time_columns], function(x) {
  # Calculate mean of the column excluding NA values
  mean_value <- mean(x, na.rm = TRUE)
  # Replace NA values with the mean
  x[is.na(x)] <- mean_value
  return(x)
})

# Print the updated data frame
print(social_media_cleaned)
```



```{R}
# Find columns with "_Time"
time_columns <- grep("_Time$", names(social_media_cleaned), value = TRUE)
time_columns

# Define additional columns to keep
additional_columns <- c("Morning_tireness", "Application Type")

# Combine time columns and additional columns to keep
columns_to_keep <- c(time_columns, additional_columns)

# Select columns to keep from the dataframe
social_media_subset <- social_media_cleaned[columns_to_keep]
```
```{R}
social_media_subset
```
```{R}
# Load the caret package
library(caret)

# Specify the column names for one-hot encoding, excluding Morning_tireness
columns <- setdiff(names(social_media_subset), "Morning_tireness")

# Create a formula for one-hot encoding excluding Morning_tireness
formula_str <- paste("Morning_tireness ~ .", collapse = " + ")

# Convert the formula string to a formula object
formula <- as.formula(formula_str)

# Create dummy variables
dummy <- dummyVars(formula, data = social_media_subset)

# Apply one-hot encoding
social_media_subset_encoded <- predict(dummy, newdata = social_media_subset)

# Convert the result to a data frame
social_media_subset_encoded <- as.data.frame(social_media_subset_encoded)

# Convert Morning_tireness back to a categorical variable
social_media_subset_encoded$Morning_tireness <- as.factor(social_media_subset$Morning_tireness)


social_media_subset_encoded1 <- social_media_subset_encoded
```



```{r}
head(social_media_subset_encoded)
```

```{r}
social_media_subset_encoded1$Morning_tireness <- as.numeric(as.factor(social_media_subset_encoded1$Morning_tireness)) - 1
social_media_subset_encoded1
```
```{r}
smp_size_raw <- floor(0.75 * nrow(social_media_subset_encoded1))
smp_size_raw
```
```{R}
train_ind_raw <- sample(nrow(social_media_subset_encoded1), size = smp_size_raw)

train_ind_raw
train_raw.df <- as.data.frame(social_media_subset_encoded1[train_ind_raw, ])
train_raw.df

test_raw.df <- as.data.frame(social_media_subset_encoded1[-train_ind_raw, ])
test_raw.df



```
```{r}

train_raw.df <- as.data.frame(social_media_subset_encoded1[train_ind_raw, ])
train_raw.df
# Assuming 'train_raw.df' is your data frame and '10' is the index of the constant variable

```


1) Model Development (2 points)
Prior probabilities of groups:
The prior probability of group 0 (0.6) is higher than group 1 (0.4), indicating that there are more observations in group 0 than in group 1.


Group means:
Group 0 tends to have higher values for Instagram_Time, Linkedin_Time, Snapchat_Time, Twitter_Time, and Whatsapp_Time compared to group 1.



Group 1 tends to have lower values for Instagram_Time, Linkedin_Time, Snapchat_Time, Twitter_Time, and Whatsapp_Time compared to group 0.


Group 0 has higher values for Youtube_Time, OTT_Time, and Reddit_Time compared to group 1.


Group 1 has lower values for Youtube_Time, OTT_Time, and Reddit_Time compared to group 0.


Coefficients of linear discriminants:

The coefficients of the linear discriminants (LD1) indicate the importance of each predictor variable in distinguishing between the two groups.


Variables with larger absolute coefficients have a greater influence on the classification.


For example, Reddit_Time has a large positive coefficient, indicating that it strongly contributes to the separation between the two groups.


Based on these results, we can infer that certain social media usage patterns and application types are associated with different levels of morning tiredness. Further analysis and interpretation may be needed to understand the specific relationships between these variables and morning tiredness.



```{r}
df.lda <- lda(formula = train_raw.df$Morning_tireness ~ ., data = train_raw.df)
df.lda

```

2) Model Acceptance (2 points)

Prior probabilities of groups:
Group 0 has a prior probability of 0.6, while Group 1 has a prior probability of 0.4. This indicates that there are more observations in Group 0 than in Group 1.


Group means:


Group 0 tends to have higher values for Instagram_Time, Linkedin_Time, Snapchat_Time, Twitter_Time, and Whatsapp_Time compared to Group 1.


Group 1 tends to have lower values for Instagram_Time, Linkedin_Time, Snapchat_Time, Twitter_Time, and Whatsapp_Time compared to Group 0.


Group 0 has higher values for Youtube_Time, OTT_Time, and Reddit_Time compared to Group 1.


Group 1 has lower values for Youtube_Time, OTT_Time, and Reddit_Time compared to Group 0.


Coefficients of linear discriminants:


The coefficients of the linear discriminants (LD1) indicate the importance of each predictor variable in distinguishing between the two groups.


Variables with larger absolute coefficients have a greater influence on the classification.


For example, Reddit_Time has a large positive coefficient, indicating that it strongly contributes to the separation between the two groups.


Based on these results, we can infer that certain social media usage patterns and application types are associated with different levels of morning tireness. Further analysis and interpretation may be needed to understand the specific relationships between these variables and morning tireness.


```{r}
train_raw.df$Morning_tireness
summary(df.lda)
print(df.lda)
par(mar = c(5, 5, 2, 2))  # Set margin size (bottom, left, top, right)
plot(df.lda)


```



4) Prediction (2 points)


Predicted Classes:

The predicted classes for the observations in the test dataset are as follows:

Observation 3 is predicted to belong to class 1.
Observation 4 is predicted to belong to class 1.
Observation 6 is predicted to belong to class 0.
Observation 9 is predicted to belong to class 1.
Observation 16 is predicted to belong to class 1.
Observation 20 is predicted to belong to class 0.


LD1 Scores:

The LD1 scores for the observations in the test dataset are also provided.

These scores represent the linear discriminant values for each observation, which are used to classify them into the respective classes.


Based on these predictions and LD1 scores, we can infer that the LDA model has assigned classes to each observation in the test dataset based on their social media usage patterns and application types. The LD1 scores provide additional information about the separation between the classes.

Further interpretation and analysis may be required to understand the implications of these results.
```{r}

df.lda.predict <- predict(df.lda, newdata = test_raw.df)
df.lda.predict$class
df.lda.predict$x

```
```{R}
# Get the posteriors as a dataframe.
df.predict.posteriors <- as.data.frame(df.lda.predict$posterior)
df.predict.posteriors
pred <- prediction(df.predict.posteriors[,2], test_raw.df$Morning_tireness)
pred

colnames(df.predict.posteriors)
str(df.predict.posteriors)
head(df.predict.posteriors)
```
```{R}
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values
plot(roc.perf)
abline(a=0, b= 1)
text(x = .25, y = .65 ,paste("AUC = ", round(auc.train[[1]],3), sep = ""))


```


5) Model Accuracy (2 points)

A model accuracy of 0.3333 indicates that the model correctly classified approximately 33.33% of the observations in the test dataset. While this accuracy might seem low, it's essential to consider the context of your specific problem and the baseline accuracy.

Inference:

The accuracy of the model suggests that it may not be performing well in predicting morning tiredness based on the provided features.


Further investigation into the features, model selection, and potential data preprocessing steps may be necessary to improve the model's performance.


It's also essential to compare the model's accuracy with a baseline accuracy. For instance, if the classes in your dataset are imbalanced (e.g., one class is much more prevalent than the other), a naive classifier that always predicts the majority class could achieve a high accuracy but may not be useful. 

In such cases, you should compare your model's accuracy against the baseline accuracy to assess its effectiveness.
```{r}
# Get the predicted classes from the LDA model
predicted_classes <- df.lda.predict$class

# Get the actual classes from the test dataset
actual_classes <- test_raw.df$Morning_tireness

# Calculate accuracy
accuracy <- mean(predicted_classes == actual_classes)
cat("Accuracy:", accuracy, "\n")

# Convert factor levels to numeric values
predicted_classes_numeric <- as.numeric(as.character(predicted_classes))
actual_classes_numeric <- as.numeric(as.character(actual_classes))

# Calculate residuals
residuals <- actual_classes_numeric - predicted_classes_numeric
cat("Residuals:", residuals, "\n")
```
3) Residual Analysis (2 points)


Residual = -1: This means that the model predicted a class of 0 (negative class), but the actual class was 1 (positive class). 

In other words, the model incorrectly classified these observations as belonging to the negative class when they actually belong to the positive class.


Residual = 0: This means that the model predicted the correct class for that observation. The model correctly classified these observations.


Interpretation:

Observation 1: The model predicted a class of 0, but the actual class was 1. This indicates a misclassification where the model incorrectly classified an observation as belonging to the negative class when it actually belongs to the positive class.


Observation 2: Similar to Observation 1, the model predicted a class of 0, but the actual class was 1, resulting in a misclassification.


Observation 3: The model predicted a class of 0, and the actual class was also 0. This indicates a correct classification where the model accurately classified an observation as belonging to the negative class.


Observation 4: Similar to Observations 1 and 2, the model incorrectly classified this observation as belonging to the negative class when it actually belongs to the positive class.


Observation 5: The model predicted a class of 0, and the actual class was also 0, indicating a correct classification

.
Observation 6: Similar to Observations 1, 2, and 4, the model incorrectly classified this observation as belonging to the negative class when it actually belongs to the positive class.
